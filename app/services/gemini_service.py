import google.generativeai as genai
from google.api_core import exceptions
import time
import logging
import json
import re
from datetime import datetime
from typing import Optional, List, Dict, Any

from app.core.config import settings
from app.db import models

logger = logging.getLogger(__name__)

class GeminiService:
    def __init__(self):
        try:
            genai.configure(api_key=settings.GOOGLE_API_KEY)
            self.generation_config = {"temperature": 0.5, "top_p": 1, "top_k": 1}
            self.model = genai.GenerativeModel(
                model_name='gemini-2.5-flash', 
                generation_config=self.generation_config
            )
            logger.info("‚úÖ Cliente Gemini inicializado com sucesso (gemini-2.5-flash).")
        except Exception as e:
            logger.error(f"üö® ERRO CR√çTICO ao configurar o Gemini: {e}")
            raise

    def _generate_with_retry(self, prompt: Any) -> genai.types.GenerateContentResponse:
        """Executa a chamada para a API Gemini com l√≥gica de retentativa."""
        max_retries = 3
        attempt = 0
        while attempt < max_retries:
            try:
                return self.model.generate_content(prompt)
            except exceptions.ResourceExhausted as e:
                attempt += 1
                logger.warning(f"Quota da API excedida (429). Tentativa {attempt}/{max_retries}.")
                match = re.search(r"retry_delay {\s*seconds: (\d+)\s*}", str(e))
                wait_time = int(match.group(1)) + 2 if match else (2 ** attempt) * 5
                logger.info(f"Aguardando {wait_time} segundos para nova tentativa...")
                time.sleep(wait_time)
            except Exception as e:
                logger.error(f"Erro inesperado ao gerar conte√∫do com Gemini: {e}")
                raise e
        raise Exception(f"N√£o foi poss√≠vel obter uma resposta da API Gemini ap√≥s {max_retries} tentativas.")

    def _replace_variables_in_dict(self, config_dict: Dict[str, Any], contact_data: models.Contact) -> Dict[str, Any]:
        """Substitui vari√°veis din√¢micas em toda a estrutura do dicion√°rio de configura√ß√£o."""
        config_str = json.dumps(config_dict)
        now = datetime.now()
        days_in_portuguese = ["Segunda-feira", "Ter√ßa-feira", "Quarta-feira", "Quinta-feira", "Sexta-feira", "S√°bado", "Domingo"]
        first_name = contact_data.nome.split(" ")[0] if contact_data.nome else ""
        
        replacements = {
            "{{nome_contato}}": first_name,
            "{{data_atual}}": now.strftime("%d/%m/%Y"),
            "{{dia_semana}}": days_in_portuguese[now.weekday()],
            "{{observacoes_contato}}": contact_data.observacoes or ""
        }
        
        for var, value in replacements.items():
            config_str = config_str.replace(var, value)
        
        return json.loads(config_str)

    def _format_history_for_prompt(self, db_history: List[dict]) -> List[Dict[str, str]]:
        """Formata o hist√≥rico do banco de dados para um formato simples de JSON."""
        history_for_ia = []
        for msg in db_history:
            role = "ia" if msg.get("role") == "assistant" else "contato"
            content = msg.get("content", "")
            history_for_ia.append({"remetente": role, "mensagem": content})
        return history_for_ia

    # --- FUN√á√ÉO AUXILIAR PARA TRANSCRI√á√ÉO REINTEGRADA ---
    def _format_db_history_to_string(self, db_history: List[dict]) -> str:
        """Formata o hist√≥rico para uma string simples, usada no contexto de an√°lise de imagem."""
        history_lines = []
        for msg in db_history:
            role_text = "Eu" if msg.get("role") == "assistant" else "Contato"
            content = msg.get("content", "")
            history_lines.append(f"- {role_text}: {content}")
        return "\n".join(history_lines)

    # --- FUN√á√ÉO 'transcribe_and_analyze_media' REINTEGRADA ---
    def transcribe_and_analyze_media(self, media_data: dict, db_history: List[dict]) -> str:
        """Transcreve √°udio ou analisa imagem/documento no contexto da conversa."""
        logger.info(f"Iniciando transcri√ß√£o/an√°lise para m√≠dia do tipo {media_data.get('mime_type')}")
        
        prompt_parts = []
        
        # L√≥gica para transcrever √°udio
        if 'audio' in media_data['mime_type']:
            task = "Sua √∫nica tarefa √© transcrever o √°udio a seguir. Retorne apenas o texto transcrito, sem adicionar nenhuma outra palavra ou formata√ß√£o."
            prompt_parts.append(task)
            prompt_parts.append(media_data)
        
        # L√≥gica para analisar imagens ou documentos
        else:
            history_string = self._format_db_history_to_string(db_history)
            task = f"""
            **Contexto da Conversa Anterior:**
            {history_string}

            **Sua Tarefa:**
            Voc√™ recebeu um arquivo (imagem ou documento) do contato. Analise o conte√∫do do arquivo no contexto da conversa acima.
            Sua resposta deve ser um resumo conciso, direto e √∫til do conte√∫do, como se fosse uma anota√ß√£o para o CRM.
            Exemplo se for uma planta baixa: "O contato enviou a planta do banheiro, destacando a √°rea do box."
            Exemplo se for um cat√°logo: "O contato enviou um cat√°logo de produtos."
            Retorne APENAS o texto do resumo.
            """
            prompt_parts.append(task)
            prompt_parts.append(media_data)

        try:
            # Reutiliza o modelo principal da classe, que √© multimodal
            response = self._generate_with_retry(prompt_parts)
            
            transcription = response.text.strip()
            logger.info(f"Transcri√ß√£o/An√°lise gerada: '{transcription[:100]}...'")
            return transcription
        except Exception as e:
            logger.error(f"Erro ao transcrever/analisar m√≠dia: {e}")
            return f"[Erro ao processar m√≠dia: {media_data.get('mime_type')}]"

    def generate_conversation_action(
        self,
        config: models.Config,
        contact: models.Contact,
        conversation_history_db: List[dict],
        mode: str
    ) -> dict:
        """
        Fun√ß√£o unificada que constr√≥i um √öNICO prompt JSON com todas as instru√ß√µes.
        """
        try:
            campaign_config = self._replace_variables_in_dict(config.prompt_config, contact)
            task_map = {
                'initial': "Gerar a PRIMEIRA mensagem de prospec√ß√£o para iniciar a conversa.",
                'reply': "Analisar a √∫ltima mensagem do contato e formular a PR√ìXIMA resposta para avan√ßar na conversa.",
                'followup': "Analisar as mensagens e decidir entre continuar o fluxo, fazer um follow-up ou se n√£o √© necess√°rio mais nada apenas retorne 'null' no campo 'mensagem_para_enviar"
            }
            formatted_history = self._format_history_for_prompt(conversation_history_db)

            master_prompt = {
                "instrucao_geral": "Voc√™ √© um assistente de prospec√ß√£o e vendas. Sua tarefa √© analisar todo este JSON e retornar sua resposta.",
                "formato_resposta_obrigatorio": {
                    "descricao": "Sua resposta DEVE ser um √∫nico objeto JSON v√°lido, sem nenhum texto ou formata√ß√£o adicional (como ```json). O objeto deve conter EXATAMENTE as tr√™s chaves a seguir:",
                    "chaves": {
                        "mensagem_para_enviar": "O texto da mensagem a ser enviada ao contato. Se decidir que n√£o deve enviar uma mensagem agora, o valor deve ser null.",
                        "nova_situacao": "Um status curto que descreva o estado atual da conversa (ex: 'Aguardando Resposta', 'Reuni√£o Agendada', 'Lead Qualificado').",
                        "observacoes": "Um resumo interno e conciso da intera√ß√£o para salvar no CRM (ex: 'Contato demonstrou interesse no produto X.')."
                    },
                    "regra_importante_variaveis": "CR√çTICO: NUNCA inclua placeholders ou vari√°veis como `{{nome_contato}}` ou `[alguma informa√ß√£o]` no campo `mensagem_para_enviar`. O texto deve ser a mensagem final e completa, pronta para ser enviada diretamente ao cliente, pois as vari√°veis j√° foram substitu√≠das."
                },
                "configuracao_campanha": campaign_config,
                "dados_atuais_conversa": {
                    "contato_nome": contact.nome,
                    "tarefa_imediata": task_map.get(mode, "Continuar a conversa de forma coerente."),
                    "historico_conversa": formatted_history
                }
            }

            final_prompt_str = json.dumps(master_prompt, ensure_ascii=False, indent=2)
            response = self._generate_with_retry(final_prompt_str)
            clean_response = response.text.strip().replace("```json", "").replace("```", "")
            return json.loads(clean_response)

        except Exception as e:
            logger.error(f"Erro ao gerar a√ß√£o de conversa√ß√£o (Modo: {mode}) com Gemini: {e}")
            return {
                "mensagem_para_enviar": None,
                "nova_situacao": "Erro IA",
                "observacoes": f"Falha da IA: {str(e)}"
            }

_gemini_service_instance = None
def get_gemini_service():
    global _gemini_service_instance
    if _gemini_service_instance is None:
        _gemini_service_instance = GeminiService()
    return _gemini_service_instance